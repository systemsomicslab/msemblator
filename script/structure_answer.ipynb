{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a4f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "from metfrag_file_processing import creat_metfrag_file\n",
    "from metfrag_struc_cmd import run_metfrag_command\n",
    "from splitting_msp import read_msp\n",
    "from msfinder_struc_cmd import run_msfinder\n",
    "from msp_to_ms import convert_msp_file_to_ms\n",
    "from sirius_struc_cmd import sirius_login, run_sirius_struc\n",
    "from creating_struc_summary import struc_summary\n",
    "from struc_utility import clear_folder, clear_folder_except, save_file, generate_unique_filename\n",
    "from struc_score_normalization import ClippingTransformer\n",
    "from msfinder_struc_summary import process_msfinder_output\n",
    "from sirius_struc_summary import process_sirius_output\n",
    "from struc_score_calc import predict_and_append, aggregate_probability_with_rank\n",
    "from metfrag_summary import process_metfrag_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6e62d",
   "metadata": {},
   "source": [
    "# sirius structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from convert_struc_data_type import normalize_rank,smiles_list_to_inchikeys\n",
    "from struc_score_normalization import ClippingTransformer\n",
    "\n",
    "def process_sirius_output(sirius_folder, machine_dir, name_adduct_df, \n",
    "                          summary_inchikey_df, summary_smiles_df, \n",
    "                          class_summary_df, smiles_score_df):\n",
    "    \"\"\"\n",
    "    Processes SIRIUS output and generates updated InChIKey, SMILES, score, and classification data.\n",
    "\n",
    "    Parameters:\n",
    "        sirius_folder (str): Directory containing SIRIUS output files.\n",
    "        machine_dir (str): Directory containing score normalization pipelines.\n",
    "        name_adduct_df (pd.DataFrame): DataFrame mapping filenames to adducts.\n",
    "        summary_inchikey_df (pd.DataFrame): Existing InChIKey summary DataFrame.\n",
    "        summary_smiles_df (pd.DataFrame): Existing SMILES summary DataFrame.\n",
    "        class_summary_df (pd.DataFrame): Existing classification summary DataFrame.\n",
    "        smiles_score_df (pd.DataFrame): Existing score summary DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sirius_inchikey_df, sirius_smiles_df, class_summary_df, smiles_score_df)\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve SIRIUS output files\n",
    "    sirius_paths = glob.glob(f\"{sirius_folder}/*/structure_candidates.tsv\")\n",
    "\n",
    "    if not sirius_paths:\n",
    "        print(f\"No SIRIUS files found in {sirius_folder}\")\n",
    "        return summary_inchikey_df, summary_smiles_df, class_summary_df, smiles_score_df\n",
    "\n",
    "    data_frames = []\n",
    "    for file in sirius_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(file, sep='\\t')\n",
    "            df['filename'] = os.path.basename(os.path.dirname(file)).split('_')[-1]\n",
    "            data_frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    if not data_frames:\n",
    "        return summary_inchikey_df, summary_smiles_df, class_summary_df, smiles_score_df\n",
    "\n",
    "    # Combine all files into a single DataFrame\n",
    "    combined_data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # Assign rank\n",
    "    combined_data[\"rank\"] = combined_data.groupby(\"filename\").cumcount() + 1\n",
    "\n",
    "    # Determine score column\n",
    "    score_column = \"CSI:FingerIDScore\" if \"CSI:FingerIDScore\" in combined_data.columns else \"score\"\n",
    "\n",
    "    # Compute score difference\n",
    "    combined_data[\"score_diff\"] = 0\n",
    "    mask = (combined_data[\"rank\"] + 1 == combined_data[\"rank\"].shift(-1).fillna(0).astype(int))\n",
    "    combined_data.loc[mask, \"score_diff\"] = (\n",
    "        combined_data[score_column] - combined_data[score_column].shift(-1)\n",
    "    )\n",
    "    combined_data[\"score_diff\"] = combined_data[\"score_diff\"].fillna(0)\n",
    "\n",
    "    # Adduct replacement\n",
    "    replace_dict = {\n",
    "        r\"\\[M \\+ H3N \\+ H\\]\\+\": \"[M+NH4]+\",\n",
    "        r\"\\[M \\+ CH2O2 - H\\]-\": \"[M+FA+H]+\"\n",
    "    }\n",
    "    for pattern, replacement in replace_dict.items():\n",
    "        combined_data[\"adduct\"] = combined_data[\"adduct\"].fillna(\"\").str.replace(pattern, replacement, regex=True)\n",
    "\n",
    "    # Load score normalization pipelines\n",
    "    sirius_score_pipeline_path = os.path.join(machine_dir, \"pipeline_CSI_FingerIDScore.pkl\")\n",
    "    sirius_SD_pipeline_path = os.path.join(machine_dir, \"pipeline_sirius_score_diff.pkl\")\n",
    "\n",
    "    score_pipeline = joblib.load(sirius_score_pipeline_path)\n",
    "    SD_pipeline = joblib.load(sirius_SD_pipeline_path)\n",
    "\n",
    "    # Select top 3 ranked candidates\n",
    "    filtered_df = combined_data.groupby('filename').head(3).copy()\n",
    "\n",
    "    # # Normalize scores\n",
    "    # filtered_df[\"normalization_Zscore\"] = score_pipeline.transform(filtered_df[[score_column]])\n",
    "    # filtered_df[\"normalization_z_score_diff\"] = SD_pipeline.transform(filtered_df[[\"score_diff\"]])\n",
    "\n",
    "    # # Prepare score calculation DataFrame\n",
    "    # sirius_score_calc_df = filtered_df[[\"filename\", \"adduct\", \"rank\", \"smiles\", \"normalization_Zscore\", \"normalization_z_score_diff\"]].copy()\n",
    "    # sirius_score_calc_df = sirius_score_calc_df.rename(columns={\"smiles\": \"SMILES\"})\n",
    "    # sirius_score_calc_df[\"tool_name\"] = \"sirius\"\n",
    "\n",
    "    # # Map adducts from `name_adduct_df`\n",
    "    # sirius_score_calc_df['adduct'] = sirius_score_calc_df['filename'].map(name_adduct_df.set_index('filename')['adduct'])\n",
    "\n",
    "    # # Apply rank normalization function\n",
    "    # normalize_rank(sirius_score_calc_df)\n",
    "\n",
    "    # Convert SMILES to InChIKey\n",
    "    filtered_df[\"InChIKey\"] = smiles_list_to_inchikeys(filtered_df[\"smiles\"])\n",
    "    filtered_df = filtered_df.astype(str).fillna('')\n",
    "\n",
    "    # Pivot InChIKey and SMILES data\n",
    "    inchikey_pivot = filtered_df.pivot(index=[\"filename\"], columns=[\"rank\"], values=[\"InChIKey\"])\n",
    "    smiles_pivot = filtered_df.pivot(index=[\"filename\"], columns=[\"rank\"], values=[\"smiles\"])\n",
    "\n",
    "    inchikey_pivot.columns = [f'sirius_structure_{col[1]}' for col in inchikey_pivot.columns.values]\n",
    "    smiles_pivot.columns = [f'sirius_structure_{col[1]}' for col in smiles_pivot.columns.values]\n",
    "\n",
    "    # Merge InChIKey data\n",
    "    sirius_inchikey_df = summary_inchikey_df.merge(inchikey_pivot.reset_index(), on=[\"filename\"], how=\"outer\")\n",
    "\n",
    "    # Merge SMILES data\n",
    "    sirius_smiles_df = summary_smiles_df.merge(smiles_pivot.reset_index(), on=[\"filename\"], how=\"outer\")\n",
    "\n",
    "    # # Extract classification data (only rank 1)\n",
    "    # sirius_class_data = filtered_df[filtered_df['rank'] == '1'][['filename', 'InChIKey', 'smiles']]\n",
    "    # sirius_class_data = sirius_class_data[(sirius_class_data['InChIKey'].str.strip() != '') & \n",
    "    #                                       (sirius_class_data['smiles'].str.strip() != '')]\n",
    "    # sirius_class_data['tool_name'] = \"SIRIUS\"\n",
    "    # sirius_class_data.columns = ['filename', 'InChIKey', 'SMILES', 'tool_name']\n",
    "\n",
    "    # Append new classification data\n",
    "    class_summary_df = pd.concat([class_summary_df, sirius_class_data], ignore_index=True)\n",
    "\n",
    "    # Append new score data\n",
    "    smiles_score_df = pd.concat([smiles_score_df, sirius_score_calc_df], ignore_index=True)\n",
    "\n",
    "    return sirius_inchikey_df, sirius_smiles_df, class_summary_df, smiles_score_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b78767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_msp = r\"D:\\nist2023\\filtered_LC_renamed_id.msp\"\n",
    "msfinder_folder = r\"D:\\python\\structure_hozon_sugukesu\\msfinder\"\n",
    "machine_dir = r\"D:\\HMT\\machine\\structure\\model_new\\model_modify_separate_top5\"\n",
    "sirius_folder = r\"D:\\nist2023\\nistsiriusoutput\"\n",
    "# sirius_folder = r\"D:\\nist2023\\nistsiriusoutput\"\n",
    "metfrag_folder = r\"D:\\nist2023\\inchikeyfilter\\metfrag_output_inchikey\"\n",
    "# answer_df = pd.read_csv(r\"D:\\nist2023\\answer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd6b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inchikeyfilter\n",
    "import pandas as pd\n",
    "input_msp = r\"D:\\nist2023\\LC_unique_records_inchikey_renamed_last.msp\"\n",
    "msfinder_folder = r\"D:\\nist2023\\inchikeyfilter\\msfinder\"\n",
    "machine_dir = r\"D:\\HMT\\machine\\structure\\model_new\\model_modify_separate_top5\"\n",
    "sirius_folder = r\"D:\\nist2023\\inchikeyfilter\\sirius\"\n",
    "# sirius_folder = r\"D:\\nist2023\\nistsiriusoutput\"\n",
    "metfrag_folder = r\"D:\\nist2023\\inchikeyfilter\\metfrag_output_inchikey\"\n",
    "answer_df = pd.read_csv(r\"D:\\nist2023\\answer_inchikey2023_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c983d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from convert_struc_data_type import read_msp_file,extract_compound_and_ionization,convert_to_canonical_smiles,normalize_rank\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "from struc_score_normalization import ClippingTransformer \n",
    "from msfinder_struc_summary import process_msfinder_output\n",
    "from sirius_struc_summary import process_sirius_output\n",
    "from struc_score_calc import predict_and_append, aggregate_probability_with_rank\n",
    "from metfrag_summary import process_metfrag_output\n",
    "\n",
    "def struc_summary(input_msp, msfinder_folder, machine_dir, sirius_folder, metfrag_folder):\n",
    "    msp_data = read_msp_file(input_msp)\n",
    "    compound_ionization_data = extract_compound_and_ionization(msp_data)\n",
    "    summary_inchikey_df = pd.DataFrame(columns=['filename', 'adduct'])\n",
    "    summary_smiles_df = pd.DataFrame(columns=['filename', 'adduct'])\n",
    "    class_summary_df = pd.DataFrame(columns=['filename','tool_name','InChIKey','SMILES'])\n",
    "    smiles_score_df=pd.DataFrame(columns=['filename',\"tool_name\",'adduct',\"rank\",\"SMILES\",\"normalization_Zscore\",\"normalization_z_score_diff\",\"normalized_rank\"])\n",
    "    name_adduct_df = pd.DataFrame(columns=['filename', 'adduct'])\n",
    "    # Assign the compound names to the 'filename' column and ionization information to the 'adduct' column\n",
    "    for idx, (compound, ionization) in enumerate(compound_ionization_data):\n",
    "        summary_inchikey_df.at[idx, 'filename'] = compound\n",
    "        summary_inchikey_df.at[idx, 'adduct'] = ionization\n",
    "        summary_smiles_df.at[idx, 'filename'] = compound\n",
    "        summary_smiles_df.at[idx, 'adduct'] = ionization\n",
    "        name_adduct_df.at[idx, 'filename'] = compound\n",
    "        name_adduct_df.at[idx, 'adduct'] = ionization\n",
    "    # msfinder summary\n",
    "    msfinder_inchikey_df, msfinder_smiles_df, class_summary_df, smiles_score_df = process_msfinder_output(msfinder_folder, machine_dir, name_adduct_df, summary_inchikey_df, summary_smiles_df, class_summary_df, smiles_score_df, top_n=5)\n",
    "    # sirius summary\n",
    "    sirius_inchikey_df, sirius_smiles_df, class_summary_df, smiles_score_df = process_sirius_output(sirius_folder, machine_dir, name_adduct_df, summary_inchikey_df, summary_smiles_df, class_summary_df, smiles_score_df, top_n=5)\n",
    "    # metfrag summary\n",
    "    metfrag_inchikey_df, metfrag_smiles_df, class_summary_df, metfrag_score_calc_df = process_metfrag_output(metfrag_folder, machine_dir, name_adduct_df, summary_inchikey_df, summary_smiles_df, smiles_score_df,class_summary_df,top_n=5)\n",
    "    # Merge summary data across all tools\n",
    "    # dataframes = [msfinder_smiles_df, sirius_smiles_df, metfrag_smiles_df]\n",
    "    # summary_smiles_df = reduce(lambda left, right: pd.merge(left, right, on=[\"filename\", \"adduct\"], how='outer'), dataframes)\n",
    "\n",
    "\n",
    "    return metfrag_inchikey_df, sirius_inchikey_df, msfinder_inchikey_df\n",
    "    # return msfinder_smiles_df, sirius_smiles_df, metfrag_smiles_df,sirius_inchikey_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70219156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\msemblator2\\script\\msfinder_struc_summary.py:47: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.0045 0.     0.0334 ... 0.1232 0.6768 0.    ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  msfinder_output_combined.loc[mask, \"score_diff\"] = (\n",
      "C:\\Users\\Taiki Hirose\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Taiki Hirose\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Taiki Hirose\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\python\\msemblator2\\script\\msfinder_struc_summary.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  smiles_score_df = pd.concat([smiles_score_df, msfinder_score_calc_df], ignore_index=True)\n",
      "d:\\python\\msemblator2\\script\\sirius_struc_summary.py:47: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_data = pd.concat(data_frames, ignore_index=True)\n",
      "d:\\python\\msemblator2\\script\\sirius_struc_summary.py:58: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[13.63583062  3.06017633 42.31733242 ... 17.81904893 49.36659002\n",
      " 22.5807001 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  combined_data.loc[mask, \"score_diff\"] = (\n",
      "C:\\Users\\Taiki Hirose\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Taiki Hirose\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Taiki Hirose\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Taiki Hirose\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "[14:41:00] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "[14:41:00] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "[14:41:00] Explicit valence for atom # 11 N, 4, is greater than permitted\n",
      "[14:41:00] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[14:41:00] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[14:41:00] Explicit valence for atom # 15 N, 4, is greater than permitted\n",
      "[14:41:02] Explicit valence for atom # 7 N, 4, is greater than permitted\n",
      "d:\\python\\msemblator2\\script\\metfrag_summary.py:59: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.         0.00955986 0.01042762 ... 0.37209198 0.07755906 0.12532214]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  combined_data.loc[mask, \"Score_Difference\"] = (\n",
      "C:\\Users\\Taiki Hirose\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Taiki Hirose\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Taiki Hirose\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metfrag_inchikey_df, sirius_inchikey, msfinder_inchikey = struc_summary(input_msp, msfinder_folder, machine_dir, sirius_folder, metfrag_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "292054a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_df = pd.read_table(r\"D:\\python\\msemblator2\\script\\msfinder\\coconutandBLEXP.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a49acafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metfrag_inchikey_df['filename'] = metfrag_inchikey_df['filename'].astype(str)\n",
    "# answer_df['Name'] = answer_df['Name'].astype(str)\n",
    "# merged_df = pd.merge(metfrag_inchikey_df, answer_df, left_on='filename', right_on='Name')\n",
    "def merge_answer_sheet(df, answer_df):\n",
    "    df['filename'] = df['filename'].astype(str)\n",
    "    answer_df['Name'] = answer_df['Name'].astype(str)\n",
    "    merged_df = pd.merge(df, answer_df, left_on='filename', right_on='Name', how='left')\n",
    "    return merged_df\n",
    "def inchikey_match(df, tool_structure_col, answer_inchikey_col,top_rank):\n",
    "    return (df[f\"{tool_structure_col}_structure_{top_rank}\"].str.split('-').str[0] == df[answer_inchikey_col]).astype(int)\n",
    "metfrag_merged = merge_answer_sheet(metfrag_inchikey_df, answer_df)\n",
    "for rank in range(1,6):\n",
    "    metfrag_merged[f'TF{rank}'] = inchikey_match(metfrag_merged, 'metfrag', 'InChIKey14', rank)\n",
    "\n",
    "sirius_merged = merge_answer_sheet(sirius_inchikey, answer_df)\n",
    "for rank in range(1,6):\n",
    "    sirius_merged[f'TF{rank}'] = inchikey_match(sirius_merged, 'sirius', 'InChIKey14', rank)\n",
    "\n",
    "msfinder_merged = merge_answer_sheet(msfinder_inchikey, answer_df)\n",
    "for rank in range(1,6):\n",
    "    msfinder_merged[f'TF{rank}'] = inchikey_match(msfinder_merged, 'msfinder', 'InChIKey14', rank)\n",
    "\n",
    "# merged_df['TF1'] = (merged_df['sirius_structure_1'].str.split('-').str[0] == merged_df['InChIKey14']).astype(int)\n",
    "# merged_df['TF2'] = (merged_df['sirius_structure_2'].str.split('-').str[0] == merged_df['InChIKey14']).astype(int)\n",
    "# merged_df['TF3'] = (merged_df['sirius_structure_3'].str.split('-').str[0] == merged_df['InChIKey14']).astype(int)\n",
    "# merged_df['TF4'] = (merged_df['sirius_structure_4'].str.split('-').str[0] == merged_df['InChIKey14']).astype(int)\n",
    "# merged_df['TF5'] = (merged_df['sirius_structure_5'].str.split('-').str[0] == merged_df['InChIKey14']).astype(int)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
